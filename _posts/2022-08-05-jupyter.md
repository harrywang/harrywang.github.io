---
layout: post
title: Configure and Use JupyterLab on Remote Ubuntu Server
tags: tutorial open-source coding
permalink: jupyter
---

I recently re-configured my Ubuntu server with JupyterLab so that I can run a long-running Python task with a large dataset, which can not be handled very well using my MacBook Pro. 

There are a number of steps I spent quite sometime to figure out, which I think I might re-use in the future and decide to write them down before I forget.

The task was a sentiment analysis of ~1.4 million hotel reviews using our fine-tuned model based on [Erlangshen-Roberta-330M-Sentiment](https://huggingface.co/IDEA-CCNL/Erlangshen-Roberta-330M-Sentiment), which took about 10 days to complete (NOTE: if the repo is private, you must get a token from HuggingFace and run `huggingface-cli login` with token first and the code also needs to be changed to use token - see my inline comments for details below). I developed a simplified version to use in this tutorial.

The following are the key steps:

- install JupyterHub on the server
- install `pyenv` to manage different versions of Python
- setup and add virtual environments to to `ipykernel` so that they are accessible from JupyterLab
- run a long-running Python task without keeping terminal open and with logging and email notification

## JupyterHub Setup and SFTP

Our system admin used this [tutorial](https://github.com/jupyterhub/jupyterhub-the-hard-way/blob/HEAD/docs/installation-guide-hard.md) to setup the JupyterHub and added my account to the `sudo` group. 

For small files, I just use JupyterLab interface to upload them to the server. For large files, I use [FileZilla](https://filezilla-project.org/) to upload.

## Python Versions

Different python versions might be needed for different projects. I use [pyenv](https://github.com/pyenv/pyenv) to manage Python versions. The following is my note for setting up pyenv on Ubuntu server, refer to [my Mac tutorial](https://harrywang.medium.com/how-to-setup-mac-for-python-development-37e5fd895151) if needed.

```
ssh hjwang@128.175.21.xxx  # ssh to remote server
sudo apt update -y  # update apt
sudo apt install -y make build-essential libssl-dev zlib1g-dev libbz2-dev libreadline-dev libsqlite3-dev wget curl llvm libncurses5-dev libncursesw5-dev xz-utils tk-dev libffi-dev liblzma-dev python-openssl git  # install dependencies
git clone https://github.com/pyenv/pyenv.git ~/.pyenv  # clone the repo
echo 'export PYENV_ROOT="$HOME/.pyenv"' >> ~/.bashrc  # setup environment
echo 'export PATH="$PYENV_ROOT/bin:$PATH"' >> ~/.bashrc  # setup environment
echo -e 'if command -v pyenv 1>/dev/null 2>&1; then\n eval "$(pyenv init -)"\nfi' >> ~/.bashrc  # setup environment
exec "$SHELL"  # restart the shell
pyenv install --list  # available versions to install 
pyenv versions  # installed versions
pyenv install 3.9.1  # install a Python version
pyenv global 3.9.1  # set global python version to use
```

Now if I type `python`, I see Python 3.9.1:

```
Python 3.9.1 (default, Aug  5 2022, 16:07:24) 
[GCC 7.5.0] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> 
```

## Virtual Environments

Setup and activate a virtual environment (here I put all virtual environments in the folder `venv` and this sample one is named `ml`):

```
python -m venv venv/ml
source venv/ml/bin/activate
```
Next, while the virtual environment is activated, we need to add it to ipykernel so that we can access it via JupyterLab:

```
pip install ipykernel
sudo env "PATH=$PATH VIRTUAL_ENV=$VIRTUAL_ENV" python -m ipykernel install --name=ml
```

Now, the new virtual environment (kernel) can be used when creating new notebook:

<img class="mx-auto" width='400' src="https://user-images.githubusercontent.com/595772/183214749-6f93ee12-d59e-466a-8482-c7e211b19692.png">


## Long-running Python Tasks

- create a `requirements.txt` with the following content:

```
pandas
torch==1.11.0
transformers
python-dotenv
sendgrid
```

then run `pip install -r requirements.txt` in the activated virtual environment.

- setup a `.env` to store the environment variables the program needs:

```
SENDGRID_API_KEY='SG.t1o-XXuERs2VIMykY81w2A.2LokhGSW0b0H9bwX-Kwa6xxx'
FROM_EMAIL='hjwang@udel.edu'
TO_EMAIL='harryjwang@gmail.com'
```

- the sample hotel review text (in Chinese) csv is provided [here](https://github.com/harrywang/absa-labeller/files/9274007/hotel-reviews.csv)

- the sample python sentiment analysis script is as follows:

<script src="https://gist.github.com/harrywang/7ebfa56bf568a8dd29885c01ed66f54d.js"></script>

The program will calculate the sentiment of each review and generate a new csv file as the result. In total, the small sample has 500 rows. The processed result is saved every 100 rows and an email notification is sent out every 200 rows.  

I use this program to show:

- how to call a HuggingFace model - see the inline comments about how to use a private HuggingFace repo.
- how to log the result using Python logging
- how to send out email notifications using SendGrid (you need to get a API token)

To run the program in the background, you can ssh to the server or use the terminal from JupyterLab, activate the virtual environment, then execute:

```
nohup python sentiment-analysis.py &
```

`&` asks the terminal to return control to you immediately and allows the command to complete in the background ([source](https://serverfault.com/questions/402496/what-does-the-ampersand-symbol-mean-with-nohup)).

The program will keep on running even if you close the terminal or close JupyterLab.

Two files will be generated:

- `log.txt` has the logging info - note that the timestamp is added automatically.

```
INFO: 08/05/2022 06:44:49 data loaded
INFO: 08/05/2022 06:44:55 model loaded
...
```

- `nohup.out` will have all outputs of the `print()` function.

Three email notifications will also be sent:

<img class="mx-auto" width='400' src="https://user-images.githubusercontent.com/595772/183221322-13637c22-f245-4d73-9a96-f1a74bf22913.png">

The logging and email notifications are very useful for long-running tasks so that I know the program is still working fine or where to restart if something went wrong.