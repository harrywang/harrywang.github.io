---
layout: post
title: A Practical Guide to Propensity Score Matching
tags: tutorial open-source teaching research
permalink: psm
date: 2022-05-25
---

> Propensity Score Matching (PSM) is a quasi-experimental method in which the researcher uses statistical techniques to construct an artificial control group by matching each treated unit with a non-treated unit of similar characteristics. Using these matches, the researcher can estimate the impact of an intervention. - [World Bank](https://dimewiki.worldbank.org/Propensity_Score_Matching)

In this tutorial, we use two datasets to show:

- why matching matters via a simple simulated example
- why propensity score matching is needed and how to do that in Python and R using a Groupon example

This is joint work with my friend [Dr. Gang Wang](https://lerner.udel.edu/faculty-staff-directory/gang-wang/). The Groupon dataset is from [his paper](https://dl.acm.org/doi/10.1145/2764919).

We have shared the [datasets](https://www.kaggle.com/datasets/harrywang/propensity-score-matching) and code (Python by me and R by Gang) on Kaggle:

- [Simple Matching (Python)](https://www.kaggle.com/code/harrywang/simple-matching)
- [Propensity Score Matching (Python)](https://www.kaggle.com/code/harrywang/propensity-score-matching-via-python)

We only focus on the key concepts and issues in this tutorial and advise the readers to go over the annotated code for details.

## Simple Matching

`smoker.csv` is a simple simulated dataset about patients with three columns:

- smoker: 1 yes, 0 no
- treatment: 1 treated (treatment group), 0 not treated (control group)
- outcome: 1 dead, 0 not dead

<img class="mx-auto" width='250' src="https://user-images.githubusercontent.com/595772/170324500-4f58ccca-af49-429d-b885-208d72eab896.png">

If we ignore the smoker status and compare the death rate in the control group (23.5%) and the treatment group (34%), we would have the following conclusion:

Given the ATE (average treatment effect) is 0.105 (0.34-0.235), the percentage of death will increase by 10.5% if the treatment is conducted. 

> So, the treatment should **NOT** be done.

Now let's look at the smoker patient ratio in control and treatment groups:

<img class="mx-auto" width='400' src="https://user-images.githubusercontent.com/595772/170330892-f1737e7f-d2d3-4ed3-868a-d024557aacee.png">

There are way more smokers among the patients in the treatment group (56%) compared with the control group (19%) - is that possible that smoking leads to a higher death rate? 

Next, we do a simple 1:1 matching so that the smoker ratio in the control and treatment groups will be the same. For each patient in the treatment group, we randomly choose a patient from the control group to match:

- if the treated patient is a smoker, we select a smoker from the control group
- if the treated patient is not a smoker, we select a non-smoker from the control group

Here, we use random sampling without replacement, i.e., once a patient in the control group is matched with a patient in the treatment group, he cannot be used to match other patients.

After matching, the smoker patient ratio in control and treatment groups is the same:

<img class="mx-auto" width='400' src="https://user-images.githubusercontent.com/595772/170335492-c5962f1f-45ec-49a3-ac7c-164383b351a5.png">

Note: given there are patents that are not matched, the total number of patients in the matched dataset is often smaller than the original dataset.

Now, if we compare the death rate in the **matched** control group (56%) and treatment group (34%), we would have the following conclusion:

Given the ATE (average treatment effect) is -0.22 (0.56-0.34), the percentage of death will increase by 22% if the treatment is conducted. 

> So, the treatment should be done.

**After matching, our conclusion about the treatment is the opposite!**

## Propensity Score Matching

In the simple matching example, we match patients only based on one binary feature: smoker or not. In real datasets used in observational studies, each observation often has many features. Matching observations with the same values across multiple features is often not feasible. 

Let's look at a Groupon example:

<img class="mx-auto" width='550' src="https://user-images.githubusercontent.com/595772/170339482-d70ef9ca-a9c1-4707-b41e-8b987f99deee.png">

Some Groupon deals have a minimal requirement, e.g., as shown in the picture above, the deal only works when there are at least 100 committed buyers. 

So, we can define:

- Control group: deals without the minimal requirement
- Treatment group: deals with minimal requirement

We are interested in: 

**Does having the minimal requirement affect the deal outcomes, such as revenue, quantity sold, and Facebook likes received?**

`groupon.csv` has the following structure:

<img class="mx-auto" src="https://user-images.githubusercontent.com/595772/170354156-4d9e5c83-6960-4595-b8ff-78363dfebef9.png">

Finding two deals from different groups with exact matches across different features, such as price, coupon_duration, featured or not, etc. would be very difficult if not possible.

Therefore, we need to use propensity score matching.

The propensity score definition is simple: 

**propensity score is the probability for an observation (a deal in this case) to be in the treatment group**

The calculation of the propensity score can then be translated into a binary classification problem: given the features of a deal, classify each deal as 0 (control) or 1 (treatment).

Two issues here:

1. what model to use for classification: logistic regression is often used.
2. what features to select: as we will illustrate later, the following features/variables should be excluded:
  - features/variables that predict treatment status perfectly, such as `min_req` feature, which the `treatment` feature is directly derived from (see the code notebook for the result of adding `min_req`).
  - features/variables that may be affected by the treatment

So, we use `prom_length`, `price`, `discount_pct`, `coupon_duration`, `featured`, `limited_supply` features to train a logistic regression model to predict target variable `treatment`:

```
X = df[['prom_length', 'price', 'discount_pct', 'coupon_duration', 'featured','limited_supply']]
y = df['treatment']

from sklearn.linear_model import LogisticRegression
lr = LogisticRegression()
lr.fit(X, y)

pred_prob = lr.predict_proba(X)  # probabilities for classes

# the propensity score (ps) is the probability of being 1 (i.e., in the treatment group)
df['ps'] = pred_prob[:, 1]

# check the overlap of ps for control and treatment using histogram
sns.histplot(data=df, x='ps', hue='treatment')

```

<img class="mx-auto" width='550' src="https://user-images.githubusercontent.com/595772/170357904-efc21019-71e2-4464-8442-ee0dd427c1f3.png">

The figure above shows major overlaps of the propensity scores in the control and treatment group, which is a good foundation for the matching, i.e., if there are no or few overlaps, it's impossible/difficult to find enough matches.

For example, if `min_req` is used to calculate the propensity score, there won't be any overlaps as shown below:

<img class="mx-auto" width='550' src="https://user-images.githubusercontent.com/595772/170391159-115ef160-c932-4907-b0f9-0127f1da4855.png">

If we plot `revenue` with `start_date`, we can see that the date is highly correlated with treatment:

<img class="mx-auto" src="https://user-images.githubusercontent.com/595772/170391325-f0e6f5a3-f567-4add-9cb4-fd47323369fe.png">

if `start_date` is used to calculate the propensity score, there is only little overlap resulting in not enough matched observations:

<img class="mx-auto" width='550' src="https://user-images.githubusercontent.com/595772/170391492-0dd0c9f1-86a3-4745-8fe9-bd9960eb6b6b.png">

The matching based on propensity score is simple:

- for each observation in the treatment, use KNN to find the top N closest neighbors in the control group based on the propensity score (here, use a fixed radius/caliper, such as 0.05 or use 25% of the standard deviation of the propensity score as radius/caliper)
- if 1:1 matching, pick the closest one as the match
- if 1:M matching, pick the M closest ones from the top N as the match
- a match cannot be reused if replacement is true
- drop observations without any match

One way to see the matching effect is to show the mean difference of the features from control vs. treatment groups before and after the match - we hope to decrease the differences via matching, i.e., the characteristics of the deals are more similar in both control and treatment groups after matching.

The following table and figure show the before/after p-values of the mean difference and the effect size for different features used for calculating the propensity score:

<img class="mx-auto" width='450' src="https://user-images.githubusercontent.com/595772/170360701-910cc7ca-355b-420b-ba62-5bd9620911c4.png">


<img class="mx-auto" src="https://user-images.githubusercontent.com/595772/170360479-2b0acda8-4aee-46dc-b8b0-ec7449a82a40.png">

We can see except that `discount_pct` and `featured` are not significant, all other features are more similar/balanced after matching.

We can then conduct t-tests (see code notebook for details) for the dependent variables in the dataset before and after the match:

- for revenue (`revenue`), p-value changed from 0.04 to 0.051. 0.051 is not significant meaning that having minimal requirements does not change revenue.
- for Facebook likes received (`fb_likes`), p-value changed from 0.004 to 0.002. Both are significant meaning that having the minimal requirement increases the facebook likes received. 

In the [Propensity Score Matching (Python)](https://www.kaggle.com/code/harrywang/propensity-score-matching-via-python) notebook, I also include the code to use [psmpy](https://towardsdatascience.com/psmpy-propensity-score-matching-in-python-a3e0cd4d2631) package, which generates similar results. Given the the package is not open-sourced yet - I cannot check the details.

## References

- [A hands-on introduction to Propensity Score use for beginners](https://towardsdatascience.com/a-hands-on-introduction-to-propensity-score-use-for-beginners-856302b632ac)
- [psmpy: Propensity Score Matching in Python](https://towardsdatascience.com/psmpy-propensity-score-matching-in-python-a3e0cd4d2631)

[Back to Top](#title)


